{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Data Cleansing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Environment Variables and Initialize API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# loading .env file\n",
    "load_dotenv()\n",
    "\n",
    "# setting OPENAI_API_KEY\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# Setting model\n",
    "llm_model = \"gpt-3.5-turbo\" \n",
    "\n",
    "# Initialize OpenAI LLM with LangChain\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name=llm_model,\n",
    "    #temperature=0.7,   # Control randomness: 0.0 is deterministic, 1.0 is very creative\n",
    "    #max_tokens=1500    # Max tokens in the response\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview Prompt:\n",
      "\n",
      "You are tasked with converting the following durations to days. These durations are a free-form text \n",
      "field on an 811 OneCall Ticket.  The Duration is how long the job should last. There may be misspellings \n",
      "or errors. If you see an estimate or range, use the highest. The minimum number of days should be 1, \n",
      "if something is 1 hour, it should be 1 day. Anything that cannot convert to a day, is error. For full days, \n",
      "enter the exact number of days. For any part of a day mentioned (like hours or half days), count each as a \n",
      "full day if the activity spans multiple days, reflecting the occupation of each calendar day. \n",
      "\n",
      "\n",
      "First column, “duration”, will be the original value (leave it exactly as it was entered). \n",
      "\n",
      "Second column, “days”, will be standardized amount in days (integer only).   \n",
      "\n",
      "Third column, \"is_estimate\",  will be binary (1 for yes, 0 for no). This used for anything that could \n",
      "be an estimate based on ranges or if language that could suggest an estimate is present. \n",
      "Example of such language would be \"about 2 days\" . Example of a range would be \"1-2 days\" \n",
      "where it could be 1 day or 2 days.  Language like \"mon to tue\" would be considered a start and \n",
      "stop date and not a range. \n",
      "\n",
      "\n",
      "Output the result as a CSV format with the columns: \"duration\", \"days\", and \"is_estimate\". \n",
      "No extra text before or after the CSV.\n",
      "\n",
      "\n",
      "Preview Prompt:\n",
      "\n",
      "You are tasked with converting the following durations to days. These durations are a free-form text \n",
      "field on an 811 OneCall Ticket.  The Duration is how long the job should last. There may be misspellings \n",
      "or errors. If you see an estimate or range, use the highest. The minimum number of days should be 1, \n",
      "if something is 1 hour, it should be 1 day. Anything that cannot convert to a day, is error. For full days, \n",
      "enter the exact number of days. For any part of a day mentioned (like hours or half days), count each as a \n",
      "full day if the activity spans multiple days, reflecting the occupation of each calendar day. \n",
      "\n",
      "\n",
      "First column, “duration”, will be the original value (leave it exactly as it was entered). \n",
      "\n",
      "Second column, “days”, will be standardized amount in days (integer only).   \n",
      "\n",
      "Third column, \"is_estimate\",  will be binary (1 for yes, 0 for no). This used for anything that could \n",
      "be an estimate based on ranges or if language that could suggest an estimate is present. \n",
      "Example of such language would be \"about 2 days\" . Example of a range would be \"1-2 days\" \n",
      "where it could be 1 day or 2 days.  Language like \"mon to tue\" would be considered a start and \n",
      "stop date and not a range. \n",
      "\n",
      "\n",
      "Output the result as a CSV format with the columns: \"duration\", \"days\", and \"is_estimate\". \n",
      "No extra text before or after the CSV.\n"
     ]
    }
   ],
   "source": [
    "# Load prompt from prompt.txt file\n",
    "with open('prompt.txt', 'r') as file:\n",
    "    prompt = file.read()\n",
    "\n",
    "print('\\nPreview Prompt:\\n')\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Data\n",
    "\n",
    "Loading <code>llm_unique_data.csv</code>, which has duplicate values removed to save on unnecessary computational costs.\n",
    "\n",
    "Using tiktoken to determin total tokens to be sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Rows: 1356\n",
      "Total Tokens: 5318\n",
      "\n",
      "Data Preview:\n",
      "\n",
      "\n",
      "Total Rows: 1356\n",
      "Total Tokens: 5318\n",
      "\n",
      "Data Preview:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    NOT APPLICABLE\n",
       "1           14 DAYS\n",
       "2             1 DAY\n",
       "3            5 DAYS\n",
       "4           2 WEEKS\n",
       "Name: DURATION, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "# Load the CSV data and assign to DataFrame\n",
    "csv_file_path = 'data/llm_unique_data.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Setting the DURATION column to llm_data\n",
    "llm_data = df['DURATION']\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# Tokenize each entry in the DURATION column and count tokens\n",
    "llm_data_tokens = llm_data.apply(lambda x: len(tokenizer.encode(str(x))))\n",
    "\n",
    "# Calculate the total number of tokens\n",
    "total_tokens = llm_data_tokens.sum()\n",
    "\n",
    "# Checking output \n",
    "print(f'\\nTotal Rows: {len(llm_data)}')\n",
    "print(f'Total Tokens: {total_tokens}')\n",
    "print('\\nData Preview:')\n",
    "display(llm_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Function to Batch <code>llm_data</code> Based on Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "max_tokens = 3000\n",
    "\n",
    "def split_data_by_token_limit(data, prompt, max_tokens=max_tokens):\n",
    "\n",
    "    \"\"\"Splits data into batches that stay within the token limit.\"\"\"\n",
    "    \n",
    "    current_batch = []\n",
    "    prompt_tokens = len(tokenizer.encode(prompt))  # Get the token count for the prompt\n",
    "    current_tokens = prompt_tokens  # Start the token count for the batch with the prompt tokens\n",
    "    \n",
    "    for row in data:\n",
    "        row = str(row)  # Ensure that the row is treated as a string\n",
    "        row_tokens = len(tokenizer.encode(row))\n",
    "        \n",
    "        # Check if adding the current row would exceed the max_tokens limit\n",
    "        if current_tokens + row_tokens > max_tokens:\n",
    "            yield current_batch  # Return the current batch when max_tokens is reached\n",
    "            current_batch = []  # Start a new batch\n",
    "            current_tokens = prompt_tokens  # Reset token count with the prompt tokens included for the new batch\n",
    "        \n",
    "        current_batch.append(row)\n",
    "        current_tokens += row_tokens  # Add the row's token count to the current batch\n",
    "    \n",
    "    if current_batch:  # Yield the last batch if there's any data left\n",
    "        yield current_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Each Batch\n",
    "\n",
    "*** eventually want to make role more specific ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the list to store results\n",
    "results = []\n",
    "\n",
    "# Loop through each batch\n",
    "for batch in split_data_by_token_limit(llm_data, prompt):\n",
    "    # Prepare the data from the current batch\n",
    "    batch_text = ', '.join(batch)\n",
    "    \n",
    "    # Combine the prompt and batch data into a single message format\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"{prompt}\\nData: {batch_text}\"}\n",
    "    ]\n",
    "\n",
    "    # Call the LLM using the .invoke() method\n",
    "    try:\n",
    "        response = llm.invoke(messages)\n",
    "        \n",
    "        # Extract the content (the results returned by the LLM)\n",
    "        content = response.content\n",
    "        \n",
    "        # Append the content to the results list\n",
    "        results.append(content)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Responses to DataFrame\n",
    "\n",
    "*** add preprocessing steps to avoid having to skip bad lines ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>days</th>\n",
       "      <th>is_estimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NOT APPLICABLE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14 DAYS</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 DAY</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 DAYS</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 WEEKS</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>68.1 HRS</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>40 HOURS</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>7 OR 8 DAYS</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>5-20 DAYS</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>2 WEEKS-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>937 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration  days  is_estimate\n",
       "0    NOT APPLICABLE   1.0          0.0\n",
       "1           14 DAYS  14.0          0.0\n",
       "2             1 DAY   1.0          0.0\n",
       "3            5 DAYS   5.0          0.0\n",
       "4           2 WEEKS  14.0          1.0\n",
       "..              ...   ...          ...\n",
       "932        68.1 HRS  69.0          0.0\n",
       "933        40 HOURS  40.0          0.0\n",
       "934     7 OR 8 DAYS   8.0          0.0\n",
       "935       5-20 DAYS  20.0          1.0\n",
       "936        2 WEEKS-   NaN          NaN\n",
       "\n",
       "[937 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Process each CSV string in results\n",
    "for content in results:\n",
    "    try:\n",
    "        # Read the CSV-formatted string into a DataFrame\n",
    "        df = pd.read_csv(io.StringIO(content), on_bad_lines='skip') # Preprocess to avoid skipping\n",
    "        df_list.append(df)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing result: {e}\")\n",
    "\n",
    "\n",
    "# Concatenate all DataFrames if any\n",
    "if df_list:\n",
    "    df_results = pd.concat(df_list, ignore_index=True)\n",
    "    display(df_results)\n",
    "\n",
    "else:\n",
    "    print(\"No valid results to convert into a DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples of Bad Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 159: 1 WEEK,,7,0\n",
      "Line 415: 30 MINS - 1 HOU,1,1\n",
      "Line 159: 1 WEEK,,7,0\n",
      "Line 415: 30 MINS - 1 HOU,1,1\n"
     ]
    }
   ],
   "source": [
    "# Combine all results into a single string\n",
    "all_results = \"\\n\".join(results)\n",
    "\n",
    "# Split the combined results into lines\n",
    "lines = all_results.split('\\n')\n",
    "\n",
    "# Inspect the problematic lines\n",
    "print(f\"Line 159: {lines[158]}\")  # Indexing starts from 0\n",
    "print(f\"Line 415: {lines[414]}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
